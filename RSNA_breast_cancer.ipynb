{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faed7be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pydicom import dcmread\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer,make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833671ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,precision_recall_fscore_support,recall_score,precision_score,fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613679e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ac8b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586501ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f994e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_P=0.1\n",
    "BATCH_SIZE=8\n",
    "SIZE=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702a00e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data_roi='/media/sef/Data/rsna-breast-cancer-detection/roi_pad_512/'\n",
    "train_data_png_path='/media/sef/Data/rsna-breast-cancer-detection/bc_1024_roi_train/'\n",
    "test_data_path='/media/sef/Data/rsna-breast-cancer-detection/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f9e51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('/media/sef/Data/rsna-breast-cancer-detection/train.csv')\n",
    "train_data=glob.glob(os.path.join(train_data_png_path,'*.png'), recursive=True)\n",
    "#train_data=glob.glob(os.path.join(train_data_path,'**/*.dcm'), recursive=True)\n",
    "train_data_png=glob.glob(os.path.join(train_data_png_path,'*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d99411",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_data_png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea6e36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_data_png[0].split('/')[6].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fa959",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_data_png[0].split('/')[6].split('.')[0].split('_')[0]\n",
    "#train_data[0].split('/')[6].split('.')[0].split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c18de9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#SimpleImputer(strategy=\"most_frequent\")\n",
    "#image_df=pd.DataFrame(train_data_png,columns=['path'])\n",
    "#image_df['image_id']=image_df['path'].str.split('/').str[6].str.split('.').str[0].str.split('_').str[1]\n",
    "#image_df['patient_id']=image_df['path'].str.split('/').str[6].str.split('.').str[0].str.split('_').str[0]\n",
    "#image_df['image_id']=image_df['path'].str.split('/').str[7].str.split('.').str[0]\n",
    "#image_df['patient_id']=image_df['path'].str.split('/').str[6]\n",
    "#image_df['image_id']=image_df['image_id'].astype(int)\n",
    "#image_df['patient_id']=image_df['patient_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ab506",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_df_merged=train_df.merge(image_df,on=['patient_id','image_id'])\n",
    "cat_imputer=SimpleImputer(strategy=\"most_frequent\")\n",
    "n_imputer=SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4af4af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95869f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e7e9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_df_merged['view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e34c45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordenc=OrdinalEncoder(handle_unknown='use_encoded_value',\n",
    "                                 unknown_value=-1)\n",
    "cat_list=['laterality','view','age','implant']\n",
    "cat_imputer=SimpleImputer(strategy=\"most_frequent\")\n",
    "X=train_df.copy()\n",
    "cat_imputer.fit(train_df[cat_list])\n",
    "X[cat_list]=cat_imputer.transform(X[cat_list])\n",
    "ordenc.fit(np.array(train_df['laterality']).reshape(-1, 1))\n",
    "X['laterality']=ordenc.transform(np.array(X['laterality']).reshape(-1, 1))\n",
    "ordenc.fit(np.array(train_df['view']).reshape(-1, 1))\n",
    "X['view']=ordenc.transform(np.array(X['view']).reshape(-1, 1))\n",
    "X['view']=X['view'].astype(int)\n",
    "X['laterality']=X['laterality'].astype(int)\n",
    "\n",
    "\n",
    "X['path'] = train_data_png_path + X[\"patient_id\"].astype(str) + \"_\" + X[\"image_id\"].astype(str) + \".png\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c932fe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069eec8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X.iloc[1:40000,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a44c37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X['path'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6d325",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X['machine_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cac144",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#n_list=['BIRADS','age']\n",
    "#cat_list=['density','laterality','difficult_negative_case','view']\n",
    "#n_pipeline=make_pipeline(\n",
    "#    SimpleImputer(strategy='median')\n",
    "#)\n",
    "#cat_pipeline1=make_pipeline(\n",
    "#    SimpleImputer(strategy=\"most_frequent\"),\n",
    "#    OneHotEncoder()\n",
    "    \n",
    "#)\n",
    "\n",
    "\n",
    "#preprocessing = ColumnTransformer([\n",
    "#    (\"num\", n_pipeline, n_list),\n",
    "#   (\"cat\", cat_pipeline, cat_list),\n",
    "#])\n",
    "#preproc=ColumnTransformer([\n",
    "#    ('n',n_pipeline,n_list),\n",
    "#   ('cat',cat_pipeline,cat_list)\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d03e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "csv_columns = ['age', 'implant']\n",
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df,transform=None,prints=False):\n",
    "        self.df=df\n",
    "        self.transform=transform\n",
    "        self.prints=prints\n",
    "    def __getitem__(self,index):\n",
    "        csv_data =  torch.from_numpy(np.array(self.df.iloc[index][csv_columns].values, \n",
    "                            dtype=np.float32))\n",
    "        path_img=self.df.iloc[index].path\n",
    "    #    dcm=dcmread(path_img)\n",
    "        img=Image.open(path_img)\n",
    "#      img=Image.fromarray(dcm.pixel_array,mode='L')\n",
    "        img=img.convert('RGB')\n",
    "        label=torch.tensor(self.df.iloc[index].cancer)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            transformed_img=self.transform(img)\n",
    "            #transformed_img = np.concatenate([transformed_img, transformed_img, transformed_img], axis=0)\n",
    "            return transformed_img,csv_data,label\n",
    "        return img,csv_data,label\n",
    "    def __len__(self):\n",
    "        return(len(self.df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de078c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import pad\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import numbers\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        max_wh = max(image.size)\n",
    "        #max_wh=max(max_wh,512)\n",
    "        p_left, p_top = [(max_wh - s) // 2 for s in image.size]\n",
    "        p_right, p_bottom = [max_wh - (s+pad) for s, pad in zip(image.size, [p_left, p_top])]\n",
    "        padding = (p_left, p_top, p_right, p_bottom)\n",
    "        return F.pad(image, padding, 0, 'constant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce52d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_pad(image):\n",
    "    max_wh = max(image.size)\n",
    "    max_wh=max(max_wh,512)\n",
    "    p_left, p_top = [(max_wh - s) // 2 for s in image.size]\n",
    "    p_right, p_bottom = [max_wh - (s+pad) for s, pad in zip(image.size, [p_left, p_top])]\n",
    "    padding = (p_left, p_top, p_right, p_bottom)\n",
    "    return F.pad(image, padding, 0, 'constant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06659464",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transform_train=transforms.Compose([\n",
    "    #transforms.RandomRotation(degrees=(-5, 5)),\n",
    "    SquarePad(),\n",
    "    #transforms.Resize((1024)),\n",
    "    transforms.RandomVerticalFlip(p=0.6),\n",
    "    transforms.RandomHorizontalFlip(p=0.6),\n",
    "    transforms.RandomRotation(degrees=(-25, 25)),\n",
    "    #transforms.RandomRotation(degrees=(, 15)),\n",
    "    #transforms.RandomResizedCrop((512, 256), scale=(0.9, 1), ratio=(0.45, 0.55)) ,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.2179, std=0.0529)\n",
    "]\n",
    ")\n",
    "transform_val=transforms.Compose([\n",
    "    SquarePad(),\n",
    "    #transforms.Resize((512)),\n",
    "    #transforms.Resize((1024)),\n",
    "    transforms.RandomVerticalFlip(p=0.6),\n",
    "    transforms.RandomHorizontalFlip(p=0.6),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=(-25, 25)),\n",
    "    #transforms.RandomResizedCrop((512, 256), scale=(0.9, 1), ratio=(0.45, 0.55)) ,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.2179, std=0.0529)\n",
    "]\n",
    ")\n",
    "transform_test=transforms.Compose([\n",
    "    SquarePad(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.2179, std=0.0529)]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee706133",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2235a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train,X_val=train_test_split(X,stratify=X['cancer'],test_size=0.1,random_state=42)#stratify=X['cancer'],shuffle=True)\n",
    "train_ds=dataset(df=X_train,transform=transform_train)\n",
    "val_ds=dataset(df=X_val,transform=transform_val)\n",
    "test_ds=dataset(df=X_val,transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ecdf6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image=(train_ds[4].__getitem__(0))\n",
    "#img =(image.transpose(1,2,0)* 255).numpy().astype(np.uint8)\n",
    "#test=Image.fromarray(img)\n",
    "\n",
    "#test\n",
    "v = image.permute(1, 2, 0)\n",
    "v -= v.min()\n",
    "v /= v.max()\n",
    "plt.imshow(v)\n",
    "#img=(image.numpy().transpose(1,2,0)).astype(np.uint8)\n",
    "#test=Image.fromarray(img)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c648c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff7a5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_val['cancer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a45ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train['view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad5ae1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def data_to_device(data):\n",
    "    \n",
    "    image, metadata, targets = data\n",
    "    return image.to('cuda'), metadata.to('cuda'), targets.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79ff60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5cdf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train=X_train['cancer'].values\n",
    "y_val=X_val['cancer'].values\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
    "class_sample_count[1]=class_sample_count[1]*4\n",
    "\n",
    "#class_weights_train=compute_class_weight(class_weight='balanced',classes=np.unique(y_train),y=y_train)\n",
    "#class_weights_train=torch.tensor(class_weights_train,dtype=torch.float)\n",
    "#class_weights_val=compute_class_weight(class_weight='balanced',classes=np.unique(y_val),y=y_val)\n",
    "#class_weights_val=torch.tensor(class_weights_val,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6299b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_sample_count[1]=class_sample_count[1]*4\n",
    "class_sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49678470",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_sample_count = np.array(\n",
    "    [len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
    "class_sample_count[1]=class_sample_count[1]*4\n",
    "\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight_train = np.array([weight[t] for t in y_train])\n",
    "samples_weight_train = torch.from_numpy(samples_weight_train)\n",
    "\n",
    "\n",
    "samples_weight_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d060e36a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_sample_count= [len(np.where(y_val == t)[0]) for t in np.unique(y_val)]\n",
    "class_sample_count[1]=928*4\n",
    "class_sample_count=np.array(class_sample_count)\n",
    "weight = 1. / class_sample_count\n",
    "\n",
    "samples_weight_val = np.array([weight[t] for t in y_val])\n",
    "samples_weight_val = torch.from_numpy(samples_weight_val)\n",
    "samples_weight_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbbef3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_sample_count\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc92f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computed_weight2(y,multi):\n",
    "    class_sample_count= [len(np.where(y == t)[0]) for t in np.unique(y)]\n",
    "    class_sample_count[1]= int((class_sample_count[1]+class_sample_count[0])*multi)\n",
    "    class_sample_count=np.array(class_sample_count)\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight_val = np.array([weight[t] for t in y])\n",
    "    samples_weight_val = torch.from_numpy(samples_weight_val)\n",
    "    return samples_weight_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_train=computed_weight2(X_train['cancer'].values,0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778876f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def computed_weight(y,multi):\n",
    "    class_sample_count= [len(np.where(y == t)[0]) for t in np.unique(y)]\n",
    "    class_sample_count[1]= class_sample_count[1]*multi\n",
    "    class_sample_count=np.array(class_sample_count)\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight_val = np.array([weight[t] for t in y])\n",
    "    samples_weight_val = torch.from_numpy(samples_weight_val)\n",
    "    return samples_weight_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63193551",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#y_train = [dataset.targets[i] for i in y_train_indices]\n",
    "\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(y_train == t)[0]) for t in np.unique(y_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d351c837",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "weights_p=WEIGHTS_P\n",
    "weight_train=computed_weight2(X_train['cancer'].values,weights_p)\n",
    "weight_val=computed_weight(X_val['cancer'].values,2)\n",
    "sampler_train =WeightedRandomSampler(weight_train.type('torch.DoubleTensor'), len(weight_train))\n",
    "#WeightedRandomSampler(samples_weight_train.type('torch.DoubleTensor'), len(samples_weight_train))\n",
    "sampler_val = WeightedRandomSampler(weight_val.type('torch.DoubleTensor'), len(weight_val))\n",
    "#WeightedRandomSampler(samples_weight_val.type('torch.DoubleTensor'), len(samples_weight_val))\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_ds,batch_size=BATCH_SIZE,num_workers=4,sampler=sampler_train)\n",
    "val_loader=torch.utils.data.DataLoader(dataset=val_ds,batch_size=BATCH_SIZE,num_workers=4)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_ds,batch_size=BATCH_SIZE,num_workers=4)\n",
    "print(len(train_ds), len(train_loader))\n",
    "\n",
    "#plt.imshow((train_ds.__getitem__(8)[0]).permute(1, 2, 0))\n",
    "#plt.imshow(train_ds.__getitem__(2)[0].permute(1, 2, 0))\n",
    "\n",
    "#image, meta = train_ds.__getitem__(1)\n",
    "#plt.imshow(train_ds.__getitem__(8)[0])\n",
    "#image.shape\n",
    "\n",
    "#print(meta)\n",
    "#print(image.shape)\n",
    "\n",
    "#print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790cb33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import timm \n",
    "test=timm.create_model('efficientnet_b0',pretrained=True,num_classes=1,drop_rate=0.99)\n",
    "seresnext50 = timm.create_model('seresnext50_32x4d',pretrained=True,drop_rate=0.9,num_classes=1)\n",
    "#timm.list_models(pretrained=True)\n",
    "#print(seresnext50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd455f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b911a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cbeca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in seresnext50.named_parameters():\n",
    "    param.requires_grad=False\n",
    "layer_to_learn=[seresnext50.layer4,seresnext50.fc,seresnext50.global_pool]#res18.layer4\n",
    "for layer in layer_to_learn:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3f6e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.cuda.is_available()\n",
    "res18 = models.resnet50(pretrained=False)\n",
    "for name,param in res18.named_parameters():\n",
    "    param.requires_grad=False\n",
    "    \n",
    "#res18.fc=nn.Linear(256, 1)\n",
    "#res18.load_state_dict(torch.load('/home/sef/Untitled Folder 1/L_R_MODEL_IMG_SIZE512_Epoch10_F1_0.755_Weight0.090.pth'),strict=False) \n",
    "#res18.fc=nn.Linear(2048, 1024)\n",
    "#res18.fc=nn.Linear(512, 512)\n",
    "#res18.conv1=nn.Conv2d(1, 64, kernel_size=7,padding=3, stride=2 )\n",
    "#res18.fc=nn.Linear(512, 512)\n",
    "\n",
    "res18.fc=nn.Linear(2048, 1)\n",
    "res18=res18.to(\"cuda\")\n",
    "\n",
    "params_to_update = res18.parameters()\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8b4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(res18)\n",
    "layer_to_learn=[res18.layer4,res18.avgpool]#res18.layer4\n",
    "for layer in layer_to_learn:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad=True\n",
    "params_to_update = res18.parameters()\n",
    "print(\"Params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e01344",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff0 = models.efficientnet_b4(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe21f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eff0 = models.efficientnet_b4(weights='EfficientNet_B4_Weights.DEFAULT')\n",
    "for name,param in eff0.named_parameters():\n",
    "    param.requires_grad=False\n",
    "#print(eff0)\n",
    "eff0.features[4][2]\n",
    "layer_to_learn=[eff0.features[3][2],eff0.features[4],eff0.features[5],eff0.features[6],eff0.features[7],eff0.features[8],eff0.classifier,eff0.avgpool]\n",
    "for layer in layer_to_learn:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad=True\n",
    "eff0.classifier[0]=nn.Dropout(p=0.8)\n",
    "eff0.classifier[1]=nn.Linear(1792, 1)\n",
    "params_to_update=eff0.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026bbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eff0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eaea06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#eff0.classifier[1]=nn.Linear(1280, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bae07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#eff0=eff0.to(\"cuda\")\n",
    "\n",
    "#params_to_update = eff0.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076645ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ResNet50Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define Feature part (IMAGE)\n",
    "        self.features = eff0\n",
    "                                      # 1000 neurons out\n",
    "        # (metadata)\n",
    "        self.csv = nn.Sequential(nn.Linear(2, 100),\n",
    "                                 nn.BatchNorm1d(100),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(p=0.3))\n",
    "        \n",
    "        # Define Classification part\n",
    "        self.classification = nn.Linear(1000+ 100, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, image, meta):\n",
    "      \n",
    "        # Image CNN\n",
    "        image = self.features(image)\n",
    "        \n",
    "        \n",
    "        # CSV FNN\n",
    "        meta = self.csv(meta)\n",
    "       \n",
    "            \n",
    "        # Concatenate layers from image with layers from csv_data\n",
    "        image_meta_data = torch.cat((image, meta), dim=1)\n",
    "        \n",
    "        # CLASSIF\n",
    "        out = self.classification(image_meta_data)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b5c21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_example = eff0.to('cuda')\n",
    "\n",
    "print(len(train_ds))\n",
    "y=X_train['cancer'].values\n",
    "#class_weights=compute_class_weight(class_weight='balanced',classes=np.unique(y),y=y)\n",
    "#class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    "#class_weights.to('cuda')\n",
    "print(seresnext50.parameters())\n",
    "\n",
    "optimizer=optim.Adam(model_example.parameters(), lr=0.001) \n",
    "#cancer_loss = nn.functional.binary_cross_entropy_with_logits(pos_weight=torch.tensor([23]).to('cuda'))\n",
    "\n",
    "#params_to_update,\n",
    "#weight=class_weights\n",
    "#loss_fn=nn.CrossEntropyLoss(pos_w``eight=torch.tensor([23]).to('cuda'))\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "#loss_fn=nn.BCELoss()\n",
    "loss_fn.to('cuda')\n",
    "#class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4214306",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchmetrics.classification import F1Score\n",
    "f1 = F1Score(task=\"binary\", num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a0ef88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for name,param in model_example.named_parameters():\n",
    " #   if param.requires_grad == True:\n",
    " #       print(\"\\t\",name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cab7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model_example.load_state_dict(torch.load('/home/sef/Untitled Folder 1/IMG_SIZE1024_Epoch15_F1_0.124_Weight0.100.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#checkpoint = torch.load('/home/sef/Untitled Folder 1/checkpoint5.pth')\n",
    "#model_example.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a0ea6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#torch.save(model_example, 'full_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18430a21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def probabilistic_f1(labels, predictions, beta=0.5):\n",
    "    y_true_count = 0\n",
    "    ctp = 0\n",
    "    cfp = 0\n",
    "\n",
    "    for idx in range(len(labels)):\n",
    "        prediction = min(max(predictions[idx], 0), 1)\n",
    "        if (labels[idx]):\n",
    "            y_true_count += 1\n",
    "            ctp += prediction\n",
    "            cfp += 1 - prediction\n",
    "        else:\n",
    "            cfp += prediction\n",
    "\n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp)\n",
    "    c_recall = ctp / y_true_count\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "        return result\n",
    "    else:\n",
    "        return 0\n",
    "def pfbeta_torch(labels, preds, beta=1):\n",
    "    preds = preds.clip(0, 1)\n",
    "    y_true_count = labels.sum()\n",
    "    ctp = preds[labels==1].sum()\n",
    "    cfp = preds[labels==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp)\n",
    "    c_recall = ctp / y_true_count\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "        return result\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dfea79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9adb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(optimizer=optimizer, mode='max', \n",
    "                                      patience=5, verbose=True, factor=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b09083",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55608897",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "f_outputs=[]\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=40, device=\"cuda\"):\n",
    "    best_f1=0.25\n",
    "    for epoch in range(1, epochs+1):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            #inputs,meta,targets = batch\n",
    "            #meta=meta.to(device)\n",
    "            inputs,meta,targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            #meta=meta.to(device)\n",
    "            targets = targets.to(device)\n",
    "            #loss = loss_fn(output, targets)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets.unsqueeze(1).float())\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            training_loss += loss.item()* inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        f_outputs=[]\n",
    "        f_targets=[]\n",
    "        test=[]\n",
    "        roc_out=[]\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs,meta,targets = batch\n",
    "                inputs = inputs.to(device)\n",
    "                #meta=meta.to(device)\n",
    "                targets = targets.to(device)\n",
    "                #preds = model(inputs).squeeze()\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output = model(inputs)\n",
    "                    loss = loss_fn(output, targets.unsqueeze(1).float())\n",
    "        \n",
    "                \n",
    "                #loss = loss_fn(output,targets) \n",
    "                \n",
    "                valid_loss += loss.data.item()* inputs.size(0)\n",
    "                #pred=torch.argmax(output,dim=1)\n",
    "                prob_preds=torch.sigmoid(output)\n",
    "                train_preds = torch.round(torch.sigmoid(output))\n",
    "                test.append(torch.max(torch.sigmoid(output)))\n",
    "                f_outputs.extend(train_preds.cpu().numpy().tolist())\n",
    "                roc_out.extend(prob_preds.cpu().numpy().tolist())\n",
    "                f_targets.extend(targets.unsqueeze(1).cpu().float().tolist())#.tolist())\n",
    "                correct = torch.eq(torch.round(torch.sigmoid(output)), targets.unsqueeze(1))\n",
    "                #correct = (train_preds.cpu() == targets.unsqueeze(1)).sum().item()\n",
    "                #correct = torch.eq(torch.argmax(output,dim=1), targets)\n",
    "                num_correct += torch.sum(correct).item()\n",
    "                num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "        #MultiLabelBinarizer().fit_transform(f_outputs)\n",
    "        #MultiLabelBinarizer().fit_transform(f_targets)\n",
    "        prob_predicts=np.concatenate(roc_out)\n",
    "        predictions = np.concatenate(f_outputs)\n",
    "        np_f_targets=np.concatenate(f_targets)\n",
    "        prob_f1_score=probabilistic_f1(np_f_targets,prob_predicts)\n",
    "        roc=roc_auc_score(np_f_targets,prob_predicts)\n",
    "        sk_fbeta_score=probabilistic_f1(np_f_targets,prob_predicts,beta=1)\n",
    "        recall=recall_score(f_targets,f_outputs,zero_division=0)\n",
    "        precision=precision_score(f_targets,f_outputs,zero_division=0)\n",
    "        scheduler.step(sk_fbeta_score)\n",
    " \n",
    "        \n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
    "            valid_loss, num_correct / num_examples))\n",
    "        #print('fbeta_score: {}'.format(sk_fbeta_score))\n",
    "        print('f1_score_beta: {}'.format(prob_f1_score))\n",
    "        print('f1_score: {}'.format(sk_fbeta_score))\n",
    "        print('recall_score: {}'.format(recall))\n",
    "        print('precision_score: {}'.format(precision))\n",
    "        print('roc_auc_score: {}'.format(roc))\n",
    "        \n",
    "        #print(f_outputs) \n",
    "        ##print(f_targets)\n",
    "        #print(predictions)\n",
    "        #print(np_f_targets)\n",
    "        model_name = f\"IMG_SIZE{SIZE}_Epoch{epoch}_F1_{sk_fbeta_score:.3f}_Weight{weights_p:.3f}.pth\"\n",
    "        if  epoch in [10,15,20,25,30]:\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "        if  sk_fbeta_score-best_f1>0.002:\n",
    "            best_f1=sk_fbeta_score\n",
    "            torch.save(model.state_dict(), model_name)    \n",
    "            \n",
    "    del inputs, targets, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94764e49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train(model_example, optimizer,loss_fn, train_loader,val_loader)\n",
    "\n",
    "\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d6d72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 9,\n",
    "            'model_state_dict': model_example.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "           \n",
    "            }, 'checkpoint9.pth')\n",
    "#train(model_example, optimizer,loss_fn, train_loader,val_loader, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score: 0.7546431791107246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd76cf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_roc=None\n",
    "def fold_train(model,df,epochs=3,device='cuda'):\n",
    "    group_fold = GroupKFold(n_splits = 3)\n",
    "    k_folds = group_fold.split(X = np.zeros(len(df)), \n",
    "                               y = df['cancer'], \n",
    "                               groups = df['patient_id'].tolist())\n",
    "\n",
    "    best_roc=None\n",
    "    for i, (train_index, valid_index) in enumerate(k_folds):\n",
    "        print(f\"---------- Fold: {i+1} ----------\")\n",
    "        train_data = df.iloc[train_index].reset_index(drop=True)\n",
    "        valid_data = df.iloc[valid_index].reset_index(drop=True)\n",
    "        weights_train=computed_weight(train_data['cancer'].values,3)\n",
    "        weights_val=computed_weight(valid_data['cancer'].values,3)\n",
    "        train_ds=dataset(df=train_data,transform=transform_train)\n",
    "        val_ds=dataset(df=valid_data,transform=transform_val)\n",
    "        weights_train=computed_weight2(train_data['cancer'].values,WEIGHTS_P)\n",
    "        weights_val=computed_weight(valid_data['cancer'].values,3)\n",
    "        sampler_train = WeightedRandomSampler(weights_train.type('torch.DoubleTensor'), len(weights_train))\n",
    "        sampler_val = WeightedRandomSampler(weights_val.type('torch.DoubleTensor'), len(weights_val))\n",
    "        train_loader=torch.utils.data.DataLoader(dataset=train_ds,batch_size=32,num_workers=4,sampler=sampler_train)\n",
    "        val_loader=torch.utils.data.DataLoader(dataset=val_ds,batch_size=32,num_workers=4)\n",
    "        for epoch in range(1, epochs+1):\n",
    "            training_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            model.train()\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "            #inputs,meta,targets = batch\n",
    "            #meta=meta.to(device)\n",
    "                inputs,meta,targets = batch\n",
    "                inputs = inputs.to(device)\n",
    "                meta=meta.to(device)\n",
    "                targets = targets.to(device)\n",
    "            #loss = loss_fn(output, targets)\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output = model(inputs,meta)\n",
    "                    loss = loss_fn(output, targets.unsqueeze(1).float())\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                training_loss += loss.item()* inputs.size(0)\n",
    "            training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "            model.eval()\n",
    "            f_outputs=[]\n",
    "            f_targets=[]\n",
    "            test=[]\n",
    "            num_correct = 0 \n",
    "            num_examples = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    inputs,meta,targets = batch\n",
    "                    inputs = inputs.to(device)\n",
    "                    meta=meta.to(device)\n",
    "                   \n",
    "                    #preds = model(inputs).squeeze()\n",
    "                    \n",
    "                    targets = targets.to(device)\n",
    "\n",
    "                    #loss = loss_fn(output,targets) \n",
    "                    \n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        output = model(inputs,meta)\n",
    "                        loss = loss_fn(output, targets.unsqueeze(1).float())\n",
    "                    valid_loss += loss.data.item()* inputs.size(0)\n",
    "                    pred=torch.argmax(output,dim=1)\n",
    "                    train_preds = torch.round(torch.sigmoid(output))\n",
    "                    test.append(torch.max(torch.sigmoid(output)))\n",
    "                    f_outputs.extend(train_preds.cpu().numpy().tolist())\n",
    "                    f_targets.extend(targets.unsqueeze(1).cpu().float().tolist())#.tolist())\n",
    "                    correct = torch.eq(torch.round(torch.sigmoid(output)), targets.unsqueeze(1))\n",
    "                    #correct = (train_preds.cpu() == targets.unsqueeze(1)).sum().item()\n",
    "                    #correct = torch.eq(torch.argmax(output,dim=1), targets)\n",
    "                    num_correct += torch.sum(correct).item()\n",
    "                    num_examples += correct.shape[0]\n",
    "            valid_loss /= len(val_loader.dataset)\n",
    "            #MultiLabelBinarizer().fit_transform(f_outputs)\n",
    "            #MultiLabelBinarizer().fit_transform(f_targets)\n",
    "            predictions = np.concatenate(f_outputs)\n",
    "            np_f_targets=np.concatenate(f_targets)\n",
    "            prob_f1_score=probabilistic_f1(np_f_targets,predictions)\n",
    "            sk_fbeta_score=probabilistic_f1(np_f_targets,predictions,beta=1)\n",
    "            recall=recall_score(f_targets,f_outputs,zero_division=0)\n",
    "            precision=precision_score(f_targets,f_outputs,zero_division=0)\n",
    "            valid_roc = roc_auc_score(f_targets,f_outputs)\n",
    "            model_name = f\"Fold{i+1}_Epoch{epoch+1}_ValidAcc{num_correct / num_examples:.3f}_ROC{valid_roc:.3f}.pth\"\n",
    "            if not best_roc: # If best_roc = None\n",
    "                best_roc = valid_roc\n",
    "                torch.save(model.state_dict(), model_name)\n",
    "                \n",
    "            if valid_roc > best_roc:\n",
    "                best_roc = valid_roc\n",
    "                torch.save(model.state_dict(), model_name)\n",
    "\n",
    "\n",
    "            print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
    "                valid_loss, num_correct / num_examples))\n",
    "            #print('fbeta_score: {}'.format(sk_fbeta_score))\n",
    "            print('f1_score_beta: {}'.format(prob_f1_score))\n",
    "            print('f1_score: {}'.format(sk_fbeta_score))\n",
    "            #print('recall_score: {}'.format(recall))\n",
    "            #print('precision_score: {}'.format(precision))\n",
    "            #print('valid_roc: {}'.format(valid_roc))\n",
    "        \n",
    "    \n",
    "    del inputs, targets, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123ecd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#model_example.load_state_dict(torch.load('/home/sef/Untitled Folder 1/IMG_SIZE512_Epoch9_F1_0.154_Weight0.100.pth')) \n",
    "#fold_train(model_example,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e67e5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test(val_loader,threshold,device='cuda',loss_fn=loss_fn,printed=True):\n",
    "    model = model_example\n",
    "    path = \"/media/sef/Data/rsna-breast-cancer-detection/Load/IMG_SIZE512_Epoch8_F1_0.196_Weight0.100.pth\" \n",
    "    model.load_state_dict(torch.load(path)) \n",
    "    valid_loss = 0.0\n",
    "    running_accuracy = 0 \n",
    "    total = 0 \n",
    "    model.eval()\n",
    "    f_outputs=[]\n",
    "    f_targets=[]\n",
    "    test=[]\n",
    "    num_correct = 0 \n",
    "    num_examples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs,meta,targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "           # meta=meta.to(device)\n",
    "            \n",
    "            #preds = model(inputs).squeeze()\n",
    "            \n",
    "            targets = targets.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets.unsqueeze(1).float())      #loss = loss_fn(output,targets) \n",
    "                    \n",
    "           \n",
    "            valid_loss += loss.data.item()* inputs.size(0)\n",
    "            pred=torch.argmax(output,dim=1)\n",
    "            train_preds = torch.where(torch.sigmoid(output)>threshold,1.0,0.0)\n",
    "            test.append(torch.max(torch.sigmoid(output)))\n",
    "            f_outputs.extend(train_preds.cpu().numpy().tolist())\n",
    "            f_targets.extend(targets.unsqueeze(1).cpu().float().tolist())#.tolist())\n",
    "            correct = torch.eq(torch.round(torch.sigmoid(output)), targets.unsqueeze(1))\n",
    "                    #correct = (train_preds.cpu() == targets.unsqueeze(1)).sum().item()\n",
    "                    #correct = torch.eq(torch.argmax(output,dim=1), targets)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "    valid_loss /= len(val_loader.dataset)\n",
    "    #MultiLabelBinarizer().fit_transform(f_outputs)\n",
    "        #MultiLabelBinarizer().fit_transform(f_targets)\n",
    "    predictions = np.concatenate(f_outputs)\n",
    "    np_f_targets=np.concatenate(f_targets)\n",
    "    prob_f1_score=probabilistic_f1(np_f_targets,predictions)\n",
    "    sk_fbeta_score=probabilistic_f1(np_f_targets,predictions,beta=1)\n",
    "    recall=recall_score(f_targets,f_outputs,zero_division=0)\n",
    "    precision=precision_score(f_targets,f_outputs,zero_division=0)\n",
    "    if printed:\n",
    "        print('Validation Loss: {:.2f}, accuracy = {:.2f}'.format(\n",
    "                    valid_loss, num_correct / num_examples))\n",
    "            #print('fbeta_score: {}'.format(sk_fbeta_score))\n",
    "        print('f1_score_beta: {}'.format(prob_f1_score))\n",
    "        print('f1_score: {}'.format(sk_fbeta_score))\n",
    "        print('recall_score: {}'.format(recall))\n",
    "        print('precision_score: {}'.format(precision))\n",
    "    else:return sk_fbeta_score\n",
    "    del inputs, targets, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b20fe5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxf1=0\n",
    "thres_res=0\n",
    "for thres in np.arange(0.0,1.1,0.1):\n",
    "    test_f1=test(test_loader,thres,printed=False)\n",
    "    if test_f1>maxf1:\n",
    "        thres_res=thres\n",
    "        maxf1=test_f1\n",
    "maxf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5685d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe2149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec68df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_pred=[]\n",
    "def pred(val_loader,device='cuda'):\n",
    "    model = model_example\n",
    "    path = \"/home/sef/Untitled Folder 1/Fold3_Epoch2_ValidAcc0.900_ROC0.857.pth\" \n",
    "    model.load_state_dict(torch.load(path)) \n",
    "    valid_loss = 0.0\n",
    "    running_accuracy = 0 \n",
    "    total = 0 \n",
    "    model.eval()\n",
    "    f_outputs=[]\n",
    "    f_targets=[]\n",
    "    test=[]\n",
    "    num_correct = 0 \n",
    "    num_examples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs,meta= batch\n",
    "            inputs = inputs.to(device)\n",
    "            meta=meta.to(device)\n",
    "            output = model(inputs,meta)\n",
    "            #preds = model(inputs).squeeze()\n",
    "\n",
    "            pred=torch.argmax(output,dim=1)\n",
    "            train_preds = torch.sigmoid(output)\n",
    "            test.append(torch.round(torch.sigmoid(output)))\n",
    "            f_outputs.extend(train_preds.cpu().numpy().tolist())\n",
    "    predictions = np.concatenate(f_outputs)\n",
    "    all_pred.extend(predictions)\n",
    "   \n",
    "  \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ca8f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344b56c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df=X_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34478de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_pred=[]\n",
    "#pred(val_loader)\n",
    "#preds = preds\n",
    "#df[\"cancer\"] = all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ced65c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f72c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df['cancer'].value_counts()\n",
    "#df['laterality']='L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce83ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#df['prediction_id'] = df['patient_id'].astype(str) + \"_\" + df['laterality']\n",
    "\n",
    "#sub = df[['prediction_id', 'cancer']].groupby(\"prediction_id\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f6f7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e070a42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32966d24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
